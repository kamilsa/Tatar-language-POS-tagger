{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxml.html as html\n",
    "import re\n",
    "import ast\n",
    "from collections import deque\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = html.parse('raw2.xml')\n",
    "root = tree.getroot()\n",
    "raw = root.findall('raw')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Без төрмәдә туганбыз, төрмәдә иҗат итәбез. Безем бөтен ча-балануларыбыз милләтебезне йота торган балыктан коткарып калу өчендер.(.) Мин бары тик татар милләтенең инкыйразын тоткарларга алынган әдип кенә». Бу юлларда, бер яктан, Г. Исхакый иҗа-тының, әдәби-эстетик карашларының нигезендә яткан концепциясе ачыла, икенче яктан, иҗат эшенең шәхси ирек, милләт азатлыгы белән дә тыгыз бәйле булуы, хәтта аларны аерып карау мөмкин түгел-леге билгеләнә; өченче яктан, чын татар әдәбиятының милли эчтәлек белән сугарылырга тиешлеге, үсеш-үзгәреш тенденциясенең миллилек принцибы белән тыгыз бәйлелеге ассызыклана. Г. Исхакыйның генерал утарында татарның борынгыдан килүче морзалар нәселе вәкилләре белән очрашу күренеше, бәхәссез, Р. Батулланың зур табышы.'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq = deque([])\n",
    "for child in list(root.iter('td'))[4]:\n",
    "#     print(child.text, child.attrib)\n",
    "    word = child.text\n",
    "    attrib = str(child.attrib)\n",
    "#     result = re.search(r'popup\\(.*\\)', attrib)\n",
    "    result = re.findall(r'\\[.*\\]', attrib)\n",
    "    attribs = ast.literal_eval(result[0])\n",
    "    lemma = '_'.join(attribs[0])\n",
    "    pos = '_'.join(attribs[1])\n",
    "    dq.appendleft((word, lemma, pos))\n",
    "raw = root.findall('raw')[0].text\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Без', 'без_без', 'N_PN')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([('табышы', 'тап', 'V'),\n",
       "       ('зур', 'зур', 'ADJ'),\n",
       "       ('Батулланың', '', ''),\n",
       "       ('Р', '', ''),\n",
       "       ('бәхәссез', 'бәхәс_бәхәс_бәхәс', 'N_N_N'),\n",
       "       ('күренеше', 'күр_күрен', 'V_V'),\n",
       "       ('очрашу', 'очрашу', 'N'),\n",
       "       ('белән', 'белән', 'CNJ'),\n",
       "       ('вәкилләре', 'вәкил', 'N'),\n",
       "       ('нәселе', 'нәсел', 'N'),\n",
       "       ('морзалар', 'морза', 'N'),\n",
       "       ('килүче', 'кил', 'V'),\n",
       "       ('борынгыдан', 'борынгы', 'ADJ'),\n",
       "       ('татарның', 'татар', 'N'),\n",
       "       ('утарында', 'утар', 'N'),\n",
       "       ('генерал', 'генерал', 'N'),\n",
       "       ('Исхакыйның', '', ''),\n",
       "       ('Г', '', ''),\n",
       "       ('ассызыклана', '', ''),\n",
       "       ('бәйлелеге', 'бәй', 'N'),\n",
       "       ('тыгыз', 'тыгыз', 'ADJ'),\n",
       "       ('белән', 'белән', 'CNJ'),\n",
       "       ('принцибы', '', ''),\n",
       "       ('миллилек', '', ''),\n",
       "       ('тенденциясенең', 'тенденция', 'N'),\n",
       "       ('үсеш-үзгәреш', '', ''),\n",
       "       ('тиешлеге', '', ''),\n",
       "       ('сугарылырга', 'сугар_сугарыл', 'V_V'),\n",
       "       ('белән', 'белән', 'CNJ'),\n",
       "       ('эчтәлек', '', ''),\n",
       "       ('милли', 'милли', 'ADJ'),\n",
       "       ('әдәбиятының', '', ''),\n",
       "       ('татар', 'татар', 'N'),\n",
       "       ('чын', 'чын', 'ADJ'),\n",
       "       ('яктан', 'як', 'N'),\n",
       "       ('өченче', 'өч', 'NUM'),\n",
       "       ('билгеләнә', 'билгелә_билгелән', 'V_V'),\n",
       "       ('түгел-леге', '', ''),\n",
       "       ('мөмкин', '', ''),\n",
       "       ('карау', 'кара', 'V'),\n",
       "       ('аерып', 'аер', 'V'),\n",
       "       ('аларны', 'алар', 'PN'),\n",
       "       ('хәтта', '', ''),\n",
       "       ('булуы', 'бул', 'V'),\n",
       "       ('бәйле', 'бәй', 'N'),\n",
       "       ('тыгыз', 'тыгыз', 'ADJ'),\n",
       "       ('дә', 'дә', 'CNJ'),\n",
       "       ('белән', '', ''),\n",
       "       ('азатлыгы', 'азат', 'N'),\n",
       "       ('милләт', 'милләт', 'N'),\n",
       "       ('ирек', 'ирек_ирек', 'V_N'),\n",
       "       ('шәхси', 'шәхси', 'ADJ'),\n",
       "       ('эшенең', 'эш', 'N'),\n",
       "       ('иҗат', 'иҗат', 'N'),\n",
       "       ('яктан', 'як', 'N'),\n",
       "       ('икенче', 'ике', 'NUM'),\n",
       "       ('ачыла', 'ач_ачыл', 'V_V'),\n",
       "       ('концепциясе', 'концепция', 'N'),\n",
       "       ('яткан', 'ят_яткан', 'V_ADJ'),\n",
       "       ('нигезендә', 'нигез', 'N'),\n",
       "       ('карашларының', 'кара_караш', 'V_N'),\n",
       "       ('әдәби-эстетик', '', ''),\n",
       "       ('иҗа-тының', '', ''),\n",
       "       ('Исхакый', '', ''),\n",
       "       ('Г', '', ''),\n",
       "       ('яктан', 'як', 'N'),\n",
       "       ('бер', 'бер_бер', 'NUM_PN'),\n",
       "       ('юлларда', 'юл', 'N'),\n",
       "       ('Бу', 'бу_бу_бу', 'V_N_PN'),\n",
       "       ('кенә', '', ''),\n",
       "       ('әдип', 'әдип', 'N'),\n",
       "       ('алынган', 'алын', 'V'),\n",
       "       ('тоткарларга', '', ''),\n",
       "       ('инкыйразын', '', ''),\n",
       "       ('милләтенең', 'милләт', 'N'),\n",
       "       ('татар', 'татар', 'N'),\n",
       "       ('тик', 'тик', 'CNJ'),\n",
       "       ('бары', 'бар_бар_бары', 'N_PN_CNJ'),\n",
       "       ('Мин', 'мин', 'PN'),\n",
       "       ('өчендер', '', ''),\n",
       "       ('калу', 'кал', 'V'),\n",
       "       ('коткарып', 'коткар', 'V'),\n",
       "       ('балыктан', 'балык', 'N'),\n",
       "       ('торган', 'тор', 'V'),\n",
       "       ('йота', 'йот', 'V'),\n",
       "       ('милләтебезне', 'милләт', 'N'),\n",
       "       ('ча-балануларыбыз', '', ''),\n",
       "       ('бөтен', 'бөтен', 'PN'),\n",
       "       ('Безем', 'без_без', 'N_PN'),\n",
       "       ('итәбез', 'ит', 'V'),\n",
       "       ('иҗат', 'иҗат', 'N'),\n",
       "       ('төрмәдә', 'төрмә', 'N'),\n",
       "       ('туганбыз', 'туган', 'ADJ'),\n",
       "       ('төрмәдә', 'төрмә', 'N'),\n",
       "       ('Без', 'без_без', 'N_PN')])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Без төрмәдә туганбыз, төрмәдә иҗат итәбез.',\n",
       " 'Безем бөтен ча-балануларыбыз милләтебезне йота торган балыктан коткарып калу өчендер.(.)',\n",
       " 'Мин бары тик татар милләтенең инкыйразын тоткарларга алынган әдип кенә».',\n",
       " 'Бу юлларда, бер яктан, Г. Исхакый иҗа-тының, әдәби-эстетик карашларының нигезендә яткан концепциясе ачыла, икенче яктан, иҗат эшенең шәхси ирек, милләт азатлыгы белән дә тыгыз бәйле булуы, хәтта аларны аерып карау мөмкин түгел-леге билгеләнә; өченче яктан, чын татар әдәбиятының милли эчтәлек белән сугарылырга тиешлеге, үсеш-үзгәреш тенденциясенең миллилек принцибы белән тыгыз бәйлелеге ассызыклана.',\n",
       " 'Г. Исхакыйның генерал утарында татарның борынгыдан килүче морзалар нәселе вәкилләре белән очрашу күренеше, бәхәссез, Р. Батулланың зур табышы.']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = nltk.tokenize.sent_tokenize(raw)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Безем',\n",
       " 'бөтен',\n",
       " 'ча-балануларыбыз',\n",
       " 'милләтебезне',\n",
       " 'йота',\n",
       " 'торган',\n",
       " 'балыктан',\n",
       " 'коткарып',\n",
       " 'калу',\n",
       " 'өчендер',\n",
       " '.',\n",
       " '(',\n",
       " '.',\n",
       " ')']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# print(tokenizer.tokenize(\"Hi, there!\"))\n",
    "# print(tokenizer.tokenize(sents[1]))\n",
    "nltk.tokenize.casual_tokenize(sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Без', 'без_без', 'N_PN') 95\n",
      "('төрмәдә', 'төрмә', 'N') 94\n",
      "('туганбыз', 'туган', 'ADJ') 93\n",
      "('төрмәдә', 'төрмә', 'N') 92\n",
      "('иҗат', 'иҗат', 'N') 91\n",
      "('итәбез', 'ит', 'V') 90\n",
      "[('Без', 'без_без', 'N_PN'), ('төрмәдә', 'төрмә', 'N'), ('туганбыз', 'туган', 'ADJ'), (',', ',', ','), ('төрмәдә', 'төрмә', 'N'), ('иҗат', 'иҗат', 'N'), ('итәбез', 'ит', 'V'), ('.', '.', '.')]\n",
      "\n",
      "\n",
      "('Безем', 'без_без', 'N_PN') 89\n",
      "('бөтен', 'бөтен', 'PN') 88\n",
      "('ча-балануларыбыз', '', '') 87\n",
      "('милләтебезне', 'милләт', 'N') 86\n",
      "('йота', 'йот', 'V') 85\n",
      "('торган', 'тор', 'V') 84\n",
      "('балыктан', 'балык', 'N') 83\n",
      "('коткарып', 'коткар', 'V') 82\n",
      "('калу', 'кал', 'V') 81\n",
      "('өчендер', '', '') 80\n",
      "[('Безем', 'без_без', 'N_PN'), ('бөтен', 'бөтен', 'PN'), ('ча-балануларыбыз', '', ''), ('милләтебезне', 'милләт', 'N'), ('йота', 'йот', 'V'), ('торган', 'тор', 'V'), ('балыктан', 'балык', 'N'), ('коткарып', 'коткар', 'V'), ('калу', 'кал', 'V'), ('өчендер', '', ''), ('.', '.', '.'), ('(', '(', '('), ('.', '.', '.'), (')', ')', ')')]\n",
      "\n",
      "\n",
      "('Мин', 'мин', 'PN') 79\n",
      "('бары', 'бар_бар_бары', 'N_PN_CNJ') 78\n",
      "('тик', 'тик', 'CNJ') 77\n",
      "('татар', 'татар', 'N') 76\n",
      "('милләтенең', 'милләт', 'N') 75\n",
      "('инкыйразын', '', '') 74\n",
      "('тоткарларга', '', '') 73\n",
      "('алынган', 'алын', 'V') 72\n",
      "('әдип', 'әдип', 'N') 71\n",
      "('кенә', '', '') 70\n",
      "[('Мин', 'мин', 'PN'), ('бары', 'бар_бар_бары', 'N_PN_CNJ'), ('тик', 'тик', 'CNJ'), ('татар', 'татар', 'N'), ('милләтенең', 'милләт', 'N'), ('инкыйразын', '', ''), ('тоткарларга', '', ''), ('алынган', 'алын', 'V'), ('әдип', 'әдип', 'N'), ('кенә', '', ''), ('»', '»', '»'), ('.', '.', '.')]\n",
      "\n",
      "\n",
      "('Бу', 'бу_бу_бу', 'V_N_PN') 69\n",
      "('юлларда', 'юл', 'N') 68\n",
      "('бер', 'бер_бер', 'NUM_PN') 67\n",
      "('яктан', 'як', 'N') 66\n",
      "('Г', '', '') 65\n",
      "('Исхакый', '', '') 64\n",
      "('иҗа-тының', '', '') 63\n",
      "('әдәби-эстетик', '', '') 62\n",
      "('карашларының', 'кара_караш', 'V_N') 61\n",
      "('нигезендә', 'нигез', 'N') 60\n",
      "('яткан', 'ят_яткан', 'V_ADJ') 59\n",
      "('концепциясе', 'концепция', 'N') 58\n",
      "('ачыла', 'ач_ачыл', 'V_V') 57\n",
      "('икенче', 'ике', 'NUM') 56\n",
      "('яктан', 'як', 'N') 55\n",
      "('иҗат', 'иҗат', 'N') 54\n",
      "('эшенең', 'эш', 'N') 53\n",
      "('шәхси', 'шәхси', 'ADJ') 52\n",
      "('ирек', 'ирек_ирек', 'V_N') 51\n",
      "('милләт', 'милләт', 'N') 50\n",
      "('азатлыгы', 'азат', 'N') 49\n",
      "('белән', '', '') 48\n",
      "('дә', 'дә', 'CNJ') 47\n",
      "('тыгыз', 'тыгыз', 'ADJ') 46\n",
      "('бәйле', 'бәй', 'N') 45\n",
      "('булуы', 'бул', 'V') 44\n",
      "('хәтта', '', '') 43\n",
      "('аларны', 'алар', 'PN') 42\n",
      "('аерып', 'аер', 'V') 41\n",
      "('карау', 'кара', 'V') 40\n",
      "('мөмкин', '', '') 39\n",
      "('түгел-леге', '', '') 38\n",
      "('билгеләнә', 'билгелә_билгелән', 'V_V') 37\n",
      "('өченче', 'өч', 'NUM') 36\n",
      "('яктан', 'як', 'N') 35\n",
      "('чын', 'чын', 'ADJ') 34\n",
      "('татар', 'татар', 'N') 33\n",
      "('әдәбиятының', '', '') 32\n",
      "('милли', 'милли', 'ADJ') 31\n",
      "('эчтәлек', '', '') 30\n",
      "('белән', 'белән', 'CNJ') 29\n",
      "('сугарылырга', 'сугар_сугарыл', 'V_V') 28\n",
      "('тиешлеге', '', '') 27\n",
      "('үсеш-үзгәреш', '', '') 26\n",
      "('тенденциясенең', 'тенденция', 'N') 25\n",
      "('миллилек', '', '') 24\n",
      "('принцибы', '', '') 23\n",
      "('белән', 'белән', 'CNJ') 22\n",
      "('тыгыз', 'тыгыз', 'ADJ') 21\n",
      "('бәйлелеге', 'бәй', 'N') 20\n",
      "('ассызыклана', '', '') 19\n",
      "[('Бу', 'бу_бу_бу', 'V_N_PN'), ('юлларда', 'юл', 'N'), (',', ',', ','), ('бер', 'бер_бер', 'NUM_PN'), ('яктан', 'як', 'N'), (',', ',', ','), ('Г', '', ''), ('.', '.', '.'), ('Исхакый', '', ''), ('иҗа-тының', '', ''), (',', ',', ','), ('әдәби-эстетик', '', ''), ('карашларының', 'кара_караш', 'V_N'), ('нигезендә', 'нигез', 'N'), ('яткан', 'ят_яткан', 'V_ADJ'), ('концепциясе', 'концепция', 'N'), ('ачыла', 'ач_ачыл', 'V_V'), (',', ',', ','), ('икенче', 'ике', 'NUM'), ('яктан', 'як', 'N'), (',', ',', ','), ('иҗат', 'иҗат', 'N'), ('эшенең', 'эш', 'N'), ('шәхси', 'шәхси', 'ADJ'), ('ирек', 'ирек_ирек', 'V_N'), (',', ',', ','), ('милләт', 'милләт', 'N'), ('азатлыгы', 'азат', 'N'), ('белән', '', ''), ('дә', 'дә', 'CNJ'), ('тыгыз', 'тыгыз', 'ADJ'), ('бәйле', 'бәй', 'N'), ('булуы', 'бул', 'V'), (',', ',', ','), ('хәтта', '', ''), ('аларны', 'алар', 'PN'), ('аерып', 'аер', 'V'), ('карау', 'кара', 'V'), ('мөмкин', '', ''), ('түгел-леге', '', ''), ('билгеләнә', 'билгелә_билгелән', 'V_V'), (';', ';', ';'), ('өченче', 'өч', 'NUM'), ('яктан', 'як', 'N'), (',', ',', ','), ('чын', 'чын', 'ADJ'), ('татар', 'татар', 'N'), ('әдәбиятының', '', ''), ('милли', 'милли', 'ADJ'), ('эчтәлек', '', ''), ('белән', 'белән', 'CNJ'), ('сугарылырга', 'сугар_сугарыл', 'V_V'), ('тиешлеге', '', ''), (',', ',', ','), ('үсеш-үзгәреш', '', ''), ('тенденциясенең', 'тенденция', 'N'), ('миллилек', '', ''), ('принцибы', '', ''), ('белән', 'белән', 'CNJ'), ('тыгыз', 'тыгыз', 'ADJ'), ('бәйлелеге', 'бәй', 'N'), ('ассызыклана', '', ''), ('.', '.', '.')]\n",
      "\n",
      "\n",
      "('Г', '', '') 18\n",
      "('Исхакыйның', '', '') 17\n",
      "('генерал', 'генерал', 'N') 16\n",
      "('утарында', 'утар', 'N') 15\n",
      "('татарның', 'татар', 'N') 14\n",
      "('борынгыдан', 'борынгы', 'ADJ') 13\n",
      "('килүче', 'кил', 'V') 12\n",
      "('морзалар', 'морза', 'N') 11\n",
      "('нәселе', 'нәсел', 'N') 10\n",
      "('вәкилләре', 'вәкил', 'N') 9\n",
      "('белән', 'белән', 'CNJ') 8\n",
      "('очрашу', 'очрашу', 'N') 7\n",
      "('күренеше', 'күр_күрен', 'V_V') 6\n",
      "('бәхәссез', 'бәхәс_бәхәс_бәхәс', 'N_N_N') 5\n",
      "('Р', '', '') 4\n",
      "('Батулланың', '', '') 3\n",
      "('зур', 'зур', 'ADJ') 2\n",
      "('табышы', 'тап', 'V') 1\n",
      "[('Г', '', ''), ('.', '.', '.'), ('Исхакыйның', '', ''), ('генерал', 'генерал', 'N'), ('утарында', 'утар', 'N'), ('татарның', 'татар', 'N'), ('борынгыдан', 'борынгы', 'ADJ'), ('килүче', 'кил', 'V'), ('морзалар', 'морза', 'N'), ('нәселе', 'нәсел', 'N'), ('вәкилләре', 'вәкил', 'N'), ('белән', 'белән', 'CNJ'), ('очрашу', 'очрашу', 'N'), ('күренеше', 'күр_күрен', 'V_V'), (',', ',', ','), ('бәхәссез', 'бәхәс_бәхәс_бәхәс', 'N_N_N'), (',', ',', ','), ('Р', '', ''), ('.', '.', '.'), ('Батулланың', '', ''), ('зур', 'зур', 'ADJ'), ('табышы', 'тап', 'V'), ('.', '.', '.')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    words = nltk.tokenize.casual_tokenize(sent)\n",
    "    res = []\n",
    "    for word in words:\n",
    "        if len(dq) > 0 and dq[-1][0].strip() == word.strip():\n",
    "            print(dq[-1], len(dq))\n",
    "            res.append(dq.pop())\n",
    "        else:\n",
    "            res.append((word, word, word))\n",
    "    print(res)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_file(filename):\n",
    "    tree = html.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    dq = deque([])\n",
    "    for child in list(root.iter('td'))[4]:\n",
    "    #     print(child.text, child.attrib)\n",
    "        word = child.text\n",
    "        attrib = str(child.attrib)\n",
    "    #     result = re.search(r'popup\\(.*\\)', attrib)\n",
    "        result = re.findall(r'\\[.*\\]', attrib)\n",
    "        attribs = ast.literal_eval(result[0])\n",
    "        lemma = '_'.join(attribs[0])\n",
    "        pos = '_'.join(attribs[1])\n",
    "        dq.appendleft((word, lemma, pos))\n",
    "    raw = root.findall('raw')[0].text\n",
    "    sents = nltk.tokenize.sent_tokenize(raw)\n",
    "    total_res = []\n",
    "    for sent in sents:\n",
    "        words = nltk.tokenize.casual_tokenize(sent)\n",
    "        res = []\n",
    "        for word in words:\n",
    "            if len(dq) != 0 and dq[-1][0].strip() == word.strip():\n",
    "                res.append(dq.pop())\n",
    "            else:\n",
    "                res.append((word, word, word))\n",
    "        total_res.append(res)\n",
    "    return total_res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('үтерү', 'үтер', 'V'),\n",
       "  ('Санала', 'сана_санал', 'V_V'),\n",
       "  ('аларда', 'алар', 'PN'),\n",
       "  ('шөһрәткә', 'шөһрәт', 'N'),\n",
       "  ('.', '.', '.')],\n",
       " [('Йа', '', ''),\n",
       "  ('Алла', 'алла_алла', 'V_N'),\n",
       "  (',', ',', ','),\n",
       "  ('күпме', 'күп_күпме', 'ADJ_PN'),\n",
       "  ('көч', 'көч', 'N'),\n",
       "  ('чыгарып', 'чыгар', 'V'),\n",
       "  ('Тудырдың', 'ту_тудыр', 'V_V'),\n",
       "  ('бу', 'бу_бу_бу', 'V_N_PN'),\n",
       "  ('җирне', 'җир', 'N'),\n",
       "  ('ни', 'ни_ни', 'PN_CNJ'),\n",
       "  ('өчен', 'өч_өчен', 'NUM_POST'),\n",
       "  ('?', '?', '?')],\n",
       " [('Бар', 'бар_бар_бар', 'V_N_PN'),\n",
       "  ('җирдә', 'җир', 'N'),\n",
       "  ('сызлану', 'сызлан', 'V'),\n",
       "  (',', ',', ','),\n",
       "  ('ялвару', 'ялвар', 'V'),\n",
       "  ('—', '', ''),\n",
       "  ('Йа', '', ''),\n",
       "  ('Алла', 'алла_алла', 'V_N'),\n",
       "  (',', ',', ','),\n",
       "  ('бар', 'бар_бар_бар', 'V_N_PN'),\n",
       "  ('бездә', 'без_без', 'N_PN'),\n",
       "  ('ни', 'ни_ни', 'PN_CNJ'),\n",
       "  ('үчең', 'үч', 'N'),\n",
       "  ('?', '?', '?')],\n",
       " [('җир', 'җир', 'N'),\n",
       "  ('һәм', 'һәм', 'CNJ'),\n",
       "  ('кан', 'кан_кан', 'V_N'),\n",
       "  ('оешкан', 'оеш_оешкан', 'V_ADJ'),\n",
       "  ('бу', 'бу_бу_бу', 'V_N_PN'),\n",
       "  ('җирдә', 'җир', 'N'),\n",
       "  (',', ',', ','),\n",
       "  ('Яралар', 'яр_ярала_яра', 'V_V_N'),\n",
       "  ('кан', 'кан_кан', 'V_N'),\n",
       "  ('белән', 'белән', 'CNJ'),\n",
       "  ('укмашкан', 'укмаш', 'V'),\n",
       "  ('.', '.', '.')],\n",
       " [('Кешеләр', 'кеше', 'N'),\n",
       "  ('түгел', 'түгел_түк_түгел', 'V_V_PN'),\n",
       "  ('без', 'без_без', 'N_PN'),\n",
       "  ('биредә', 'бире_биредә', 'PN_PN'),\n",
       "  ('—', '', ''),\n",
       "  ('Номерлар', 'номерла', 'V'),\n",
       "  ('гына', 'гына', 'CNJ'),\n",
       "  ('без', 'без_без', 'N_PN'),\n",
       "  ('тоташтан', 'тоташ', 'ADJ'),\n",
       "  ('.', '.', '.')],\n",
       " [('558', '', ''),\n",
       "  ('Бастым', 'бас', 'V'),\n",
       "  ('мин', 'мин', 'PN'),\n",
       "  ('!', '!', '!')],\n",
       " [('җиңдем', 'җиң', 'V'),\n",
       "  ('мин', 'мин', 'PN'),\n",
       "  ('куркуны', 'курку', 'N'),\n",
       "  ('!', '!', '!')]]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_file('data/raw31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "total = []\n",
    "for filename in os.listdir('data'):\n",
    "    if filename[:3] == 'raw':\n",
    "        if filename == 'raw22':\n",
    "            total += process_file('data/' + filename)[:4]\n",
    "        elif filename == 'raw29':\n",
    "            total += process_file('data/' + filename)[:2]\n",
    "        else:\n",
    "            total += process_file(\"data/\" + filename)\n",
    "len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = lambda x: ' '.join(list(map(lambda x: '_'.join(x), x)))\n",
    "sents = list(map(p, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('sents.txt', 'w')\n",
    "f.write('\\n'.join(sents))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('sents.txt', 'r')\n",
    "sents = f.readlines()[:100]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def get_sents_4day(filename):\n",
    "#     f = open('sents.txt', 'r')\n",
    "    f = io.open(filename, 'r',encoding='utf-8')\n",
    "    raw_sents = f.readlines()[:100]\n",
    "    f.close()\n",
    "    \n",
    "    sents = []\n",
    "    for line in raw_sents:\n",
    "#         line = str(line, 'utf-8')\n",
    "        words = line.split()\n",
    "        p = lambda x: x[0] + '_' + x[1] + '_' + x[2]\n",
    "        words = list(map(lambda x: p(x.split('_')), words))\n",
    "        sents.append(words)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = get_sents_4day('sents.txt')[:100]\n",
    "train_sents = Z[:70]\n",
    "test_sents = Z[70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = set()\n",
    "def save_to_conll(filename, sents):\n",
    "    f = open(filename, 'w')\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            text, nf, pos = word.split('_')\n",
    "            words.add(text)\n",
    "            f.write(pos + '\\t' + text + '\\t' + nf+ '\\n')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "save_to_conll('train.conll', train_sents)\n",
    "save_to_conll('test.conll', test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1031"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word_tag = sent[i].split('_')\n",
    "    word = word_tag[0]\n",
    "    postag = word_tag[1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "#         'postag=' + postag,\n",
    "#         'postag[:2]=' + postag[:2],\n",
    "        'word.isuser=%s' % str(word[:1] == '@'),\n",
    "        'word.ishashtag=%s' % str(word[:1] == '#'),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "#             '-1:postag=' + postag1,\n",
    "#             '-1:postag[:2]=' + postag1[:2],\n",
    "            '-1:word.isuser=%s' % str(word[:1] == '@'),\n",
    "            '-1:word.ishashtag=%s' % str(word[:1] == '#'),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "#             '+1:postag=' + postag1,\n",
    "#             '+1:postag[:2]=' + postag1[:2],\n",
    "            '+1:word.isuser=%s' % str(word[:1] == '@'),\n",
    "            '+1:word.ishashtag=%s' % str(word[:1] == '#'),              \n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [word_tag.split('_')[1] for word_tag in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias',\n",
       " 'word.lower=ләкин',\n",
       " 'word[-3:]=кин',\n",
       " 'word[-2:]=ин',\n",
       " 'word.isupper=False',\n",
       " 'word.istitle=True',\n",
       " 'word.isdigit=False',\n",
       " 'word.isuser=False',\n",
       " 'word.ishashtag=False',\n",
       " 'BOS',\n",
       " '+1:word.lower=ү',\n",
       " '+1:word.istitle=False',\n",
       " '+1:word.isupper=False',\n",
       " '+1:word.isuser=False',\n",
       " '+1:word.ishashtag=False']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.4 ms, sys: 4.27 ms, total: 47.7 ms\n",
      "Wall time: 73.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\u2014' in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-319-35e39e0bcfed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"crf = sklearn_crfsuite.CRF(\\n    algorithm='lbfgs',\\n    c1=0.1,\\n    c2=0.1,\\n    max_iterations=100,\\n    all_possible_transitions=True\\n)\\ncrf.fit(X_train, y_train)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kamil/miniconda3/envs/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/kamil/miniconda3/envs/venv/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kamil/miniconda3/envs/venv/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/kamil/miniconda3/envs/venv/lib/python3.5/site-packages/sklearn_crfsuite/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_dev, y_dev)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer.append (pycrfsuite/_pycrfsuite.cpp:3447)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/kamil/miniconda3/envs/venv/lib/python3.5/site-packages/pycrfsuite/_pycrfsuite.cpython-35m-darwin.so\u001b[0m in \u001b[0;36mvector.from_py.__pyx_convert_vector_from_py_std_3a__3a_string (pycrfsuite/_pycrfsuite.cpp:9885)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/kamil/miniconda3/envs/venv/lib/python3.5/site-packages/pycrfsuite/_pycrfsuite.cpython-35m-darwin.so\u001b[0m in \u001b[0;36mstring.from_py.__pyx_convert_string_from_py_std__in_string (pycrfsuite/_pycrfsuite.cpp:9777)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\u2014' in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:venv]",
   "language": "python",
   "name": "conda-env-venv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
